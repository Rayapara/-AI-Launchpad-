# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xin8jjOcPugkAwqPbskvY1FiS9REazCZ
"""

# prompt: create a simplified unsupervised learning assignment using the classic Iris dataset. The goal is to classify iris species based on their features. This example will involve data loading, preprocessing, training a classifier, evaluate its performance and make predictions using silhouette score

import pandas as pd
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Load the Iris dataset
iris = load_iris()

# Convert to a DataFrame
data = pd.DataFrame(data=iris.data, columns=iris.feature_names)
target = pd.Series(iris.target, name='target')


# Add the species column
data['species'] = iris.target

# Save the DataFrame to a CSV file
data.to_csv("iris_dataset.csv", index=False)

print("Dataset saved to iris_dataset.csv")

# Preprocess the data
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)

print("I am done till data preprosssing")

# Determine optimal number of clusters using Silhouette Score
silhouette_scores = []
for n_clusters in range(2, 11):
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    cluster_labels = kmeans.fit_predict(scaled_data)
    silhouette_avg = silhouette_score(scaled_data, cluster_labels)
    silhouette_scores.append(silhouette_avg)

print("I am done till determining the clusters")

# Plot Silhouette Scores
plt.figure(figsize=(8, 6))
plt.plot(range(2, 11), silhouette_scores, marker='o')
plt.xlabel("Number of Clusters")
plt.ylabel("Silhouette Score")
plt.title("Silhouette Score for Different Number of Clusters")
plt.show()

print("I am done till Silhouette score plotting")

# Train the KMeans model with the optimal number of clusters
# (e.g., based on the highest silhouette score)
optimal_n_clusters = 3 # Based on the common knowledge of the Iris dataset
kmeans = KMeans(n_clusters=optimal_n_clusters, random_state=42)
kmeans.fit(scaled_data)
cluster_labels = kmeans.predict(scaled_data)


print("I am done till Training part using KMeans")


# Evaluate the model using the Silhouette Score
silhouette_avg = silhouette_score(scaled_data, cluster_labels)
print(f"Silhouette Score: {silhouette_avg}")


print("I am done till Evaluating the Model")


# Example Predictions:  Assign cluster labels to new data
new_data = [[7.5, 5.1, 3.5, 1.4, 0.2], [4.5, 6.3, 3.3, 6.0, 2.5]]
scaled_new_data = scaler.transform(new_data)
new_predictions = kmeans.predict(scaled_new_data)
print(f"Predictions for new data points: {new_predictions}")
